{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c34e2c-7e4c-48c7-9f0f-47e72834a413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:07.990310Z",
     "iopub.status.busy": "2025-07-30T01:14:07.989949Z",
     "iopub.status.idle": "2025-07-30T01:14:07.994490Z",
     "shell.execute_reply": "2025-07-30T01:14:07.993775Z",
     "shell.execute_reply.started": "2025-07-30T01:14:07.990286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Data Transformation Pipeline\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Data Transformation Pipeline\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91601180-d000-42e2-8982-3cdd41d575f0",
   "metadata": {},
   "source": [
    "# Data Transformation Pipeline for MLOps Using SageMaker Jupyter Notebooks\n",
    "`This notebook demonstrates key data transformation techniques commonly used in machine learning pipelines. It follows MLOps best practices for data preprocessing and feature engineering using AWS SageMaker JupyterLab.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880256bb-d076-4060-adaa-ad2fc830af7d",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "### üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e973b107-b357-4dd0-b794-b04a0f3e3c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:07.995992Z",
     "iopub.status.busy": "2025-07-30T01:14:07.995674Z",
     "iopub.status.idle": "2025-07-30T01:14:11.255184Z",
     "shell.execute_reply": "2025-07-30T01:14:11.254219Z",
     "shell.execute_reply.started": "2025-07-30T01:14:07.995971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "SageMaker Role: arn:aws:iam::975050014577:role/cfst-4286-e969e805783ab24d43-SageMakerExecutionRole-vM3vGv0JNhl6\n",
      "Default Bucket: sagemaker-us-east-1-975050014577\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 1: Setup Environment\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Default Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9baa537-063a-44cd-a4c2-6aa4366a9998",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 2: Data Generation\n",
    "Creating a realistic dataset that simulates common data quality challenges found in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4676e5-804d-4d6e-8781-b03b8092be7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:11.257201Z",
     "iopub.status.busy": "2025-07-30T01:14:11.256835Z",
     "iopub.status.idle": "2025-07-30T01:14:12.037097Z",
     "shell.execute_reply": "2025-07-30T01:14:12.036092Z",
     "shell.execute_reply.started": "2025-07-30T01:14:11.257171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created and uploaded to data/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records\n",
    "num_records = 50000\n",
    "\n",
    "# Generate random data\n",
    "data = {\n",
    "    \"id\": np.arange(1, num_records + 1),\n",
    "    \"name\": [f\"Name_{i}\" for i in np.random.randint(1, 1000, num_records)],\n",
    "    \"age\": np.random.randint(18, 80, num_records),\n",
    "    \"salary\": np.random.choice([50000, 60000, 70000, None], num_records),\n",
    "    \"hire_date\": [\n",
    "        (datetime.now() - timedelta(days=random.randint(0, 3650))).strftime(\"%Y-%m-%d\")\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"profile\": [\n",
    "        json.dumps({\n",
    "            \"address\": f\"Street {random.randint(1, 100)}, City {random.randint(1, 50)}\",\n",
    "            \"phone\": f\"{random.randint(1000000000, 9999999999)}\",\n",
    "            \"email\": f\"email_{random.randint(1, 1000)}@example.com\"\n",
    "        })\n",
    "        if random.random() > 0.1 else None\n",
    "        for _ in range(num_records)\n",
    "    ],\n",
    "    \"department\": np.random.choice([\"HR\", \"IT\", \"Finance\", \"Marketing\", None], num_records),\n",
    "    \"bonus\": [None if random.random() > 0.9 else random.randint(1000, 10000) for _ in range(num_records)]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some NaN values randomly\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.05), replace=False), \"age\"] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=int(num_records * 0.1), replace=False), \"salary\"] = np.nan\n",
    "\n",
    "# Ensure 'data' folder exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"data/mock_data.csv\", index=False)\n",
    "print(\"Dataset created and uploaded to data/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d5e28-a7dc-40f4-8767-6ad631e3e17d",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Step 3: Upload Source Data to S3\n",
    "Upload the source CSV dataset to input location in S3 (default bucket)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbf0e65-caee-417a-bddc-f8533c6c613c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:12.038714Z",
     "iopub.status.busy": "2025-07-30T01:14:12.038079Z",
     "iopub.status.idle": "2025-07-30T01:14:12.332102Z",
     "shell.execute_reply": "2025-07-30T01:14:12.331508Z",
     "shell.execute_reply.started": "2025-07-30T01:14:12.038681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-975050014577/input/mock_data.csv\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('data/mock_data.csv', bucket, 'input/mock_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/input/mock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781eaf7-4980-43c7-8608-746ad3666a94",
   "metadata": {},
   "source": [
    "## 2. Data Exploration  \n",
    "Load the raw dataset and perform initial data profiling. \n",
    "This step is crucial for understanding data quality and structure. \n",
    "\n",
    "### Step 1: Load the CSV File from S3 into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23bb077-5661-4295-8e50-9c99e735cd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:12.334282Z",
     "iopub.status.busy": "2025-07-30T01:14:12.334029Z",
     "iopub.status.idle": "2025-07-30T01:14:12.934016Z",
     "shell.execute_reply": "2025-07-30T01:14:12.933124Z",
     "shell.execute_reply.started": "2025-07-30T01:14:12.334262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "üìè Dataset shape: (50000, 8)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(f's3://{bucket}/input/mock_data.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìè Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: mock_data.csv not found. Please run create_dataset.py first.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43e7b6-38aa-4919-8b13-17e228bdb968",
   "metadata": {},
   "source": [
    "### Step 2: Analyse the Data  \n",
    "Perform comprehensive data analysis to understand:\n",
    "- Data types and memory usage\n",
    "- Missing values pattern\n",
    "- Statistical distribution\n",
    "- Unique values and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34776ea8-2b8e-4561-b63d-277229f87b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:12.935305Z",
     "iopub.status.busy": "2025-07-30T01:14:12.934868Z",
     "iopub.status.idle": "2025-07-30T01:14:12.958194Z",
     "shell.execute_reply": "2025-07-30T01:14:12.957014Z",
     "shell.execute_reply.started": "2025-07-30T01:14:12.935282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>{\"address\": \"Street 40, City 17\", \"phone\": \"92...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>7236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>24.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>{\"address\": \"Street 82, City 15\", \"phone\": \"42...</td>\n",
       "      <td>HR</td>\n",
       "      <td>9162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>8982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>{\"address\": \"Street 12, City 18\", \"phone\": \"42...</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1856.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date  \\\n",
       "0   1  Name_103   NaN      NaN  2025-05-16   \n",
       "1   2  Name_436  24.0  70000.0  2022-10-12   \n",
       "2   3  Name_861  33.0      NaN  2022-08-12   \n",
       "3   4  Name_271  50.0  50000.0  2017-03-29   \n",
       "4   5  Name_107  50.0  70000.0  2016-04-18   \n",
       "\n",
       "                                             profile department   bonus  \n",
       "0  {\"address\": \"Street 40, City 17\", \"phone\": \"92...  Marketing  7236.0  \n",
       "1  {\"address\": \"Street 82, City 15\", \"phone\": \"42...         HR  9162.0  \n",
       "2                                                NaN  Marketing     NaN  \n",
       "3                                                NaN    Finance  8982.0  \n",
       "4  {\"address\": \"Street 12, City 18\", \"phone\": \"42...  Marketing  1856.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows from the loaded DataFrame\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de2652a-52a8-4ba6-97df-457a332f3cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:12.960757Z",
     "iopub.status.busy": "2025-07-30T01:14:12.959996Z",
     "iopub.status.idle": "2025-07-30T01:14:12.995742Z",
     "shell.execute_reply": "2025-07-30T01:14:12.995009Z",
     "shell.execute_reply.started": "2025-07-30T01:14:12.960703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Types & Non-Null Counts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          50000 non-null  int64  \n",
      " 1   name        50000 non-null  object \n",
      " 2   age         47500 non-null  float64\n",
      " 3   salary      33848 non-null  float64\n",
      " 4   hire_date   45063 non-null  object \n",
      " 5   profile     44949 non-null  object \n",
      " 6   department  39884 non-null  object \n",
      " 7   bonus       45026 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the summary of the DataFrame\n",
    "print(\"\\nüìä Data Types & Non-Null Counts:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab79f216-1000-4333-9310-944de2d8f498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:12.997095Z",
     "iopub.status.busy": "2025-07-30T01:14:12.996792Z",
     "iopub.status.idle": "2025-07-30T01:14:13.045314Z",
     "shell.execute_reply": "2025-07-30T01:14:13.044566Z",
     "shell.execute_reply.started": "2025-07-30T01:14:12.997069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2ee607-aeae-4087-81ab-3e5da46f4346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.046563Z",
     "iopub.status.busy": "2025-07-30T01:14:13.046092Z",
     "iopub.status.idle": "2025-07-30T01:14:13.055344Z",
     "shell.execute_reply": "2025-07-30T01:14:13.054717Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.046541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', 'Finance', nan, 'IT'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26686b8-70c2-4419-87ad-c5bde83cced9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.056753Z",
     "iopub.status.busy": "2025-07-30T01:14:13.056426Z",
     "iopub.status.idle": "2025-07-30T01:14:13.147449Z",
     "shell.execute_reply": "2025-07-30T01:14:13.146781Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.056727Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>profile</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>47500.00000</td>\n",
       "      <td>33848.000000</td>\n",
       "      <td>45063</td>\n",
       "      <td>44949</td>\n",
       "      <td>39884</td>\n",
       "      <td>45026.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3651</td>\n",
       "      <td>44949</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Name_794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>{\"address\": \"Street 91, City 46\", \"phone\": \"44...</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>10074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.50440</td>\n",
       "      <td>59940.616875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5474.621530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.90915</td>\n",
       "      <td>8166.619236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2584.921709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12500.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25000.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5465.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37500.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7697.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      name          age        salary   hire_date  \\\n",
       "count   50000.000000     50000  47500.00000  33848.000000       45063   \n",
       "unique           NaN       999          NaN           NaN        3651   \n",
       "top              NaN  Name_794          NaN           NaN  2018-11-01   \n",
       "freq             NaN        73          NaN           NaN          27   \n",
       "mean    25000.500000       NaN     48.50440  59940.616875         NaN   \n",
       "std     14433.901067       NaN     17.90915   8166.619236         NaN   \n",
       "min         1.000000       NaN     18.00000  50000.000000         NaN   \n",
       "25%     12500.750000       NaN     33.00000  50000.000000         NaN   \n",
       "50%     25000.500000       NaN     48.00000  60000.000000         NaN   \n",
       "75%     37500.250000       NaN     64.00000  70000.000000         NaN   \n",
       "max     50000.000000       NaN     79.00000  70000.000000         NaN   \n",
       "\n",
       "                                                  profile department  \\\n",
       "count                                               44949      39884   \n",
       "unique                                              44949          4   \n",
       "top     {\"address\": \"Street 91, City 46\", \"phone\": \"44...         IT   \n",
       "freq                                                    1      10074   \n",
       "mean                                                  NaN        NaN   \n",
       "std                                                   NaN        NaN   \n",
       "min                                                   NaN        NaN   \n",
       "25%                                                   NaN        NaN   \n",
       "50%                                                   NaN        NaN   \n",
       "75%                                                   NaN        NaN   \n",
       "max                                                   NaN        NaN   \n",
       "\n",
       "               bonus  \n",
       "count   45026.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean     5474.621530  \n",
       "std      2584.921709  \n",
       "min      1000.000000  \n",
       "25%      3248.000000  \n",
       "50%      5465.000000  \n",
       "75%      7697.000000  \n",
       "max     10000.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistical summary for numeric coloums\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0fa73b-9bea-4d43-acda-d21a38b7e443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.150520Z",
     "iopub.status.busy": "2025-07-30T01:14:13.150141Z",
     "iopub.status.idle": "2025-07-30T01:14:13.168521Z",
     "shell.execute_reply": "2025-07-30T01:14:13.167894Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.150496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing Values Analysis:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "name              0\n",
       "age            2500\n",
       "salary        16152\n",
       "hire_date      4937\n",
       "profile        5051\n",
       "department    10116\n",
       "bonus          4974\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n‚ùì Missing Values Analysis:\\n\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ccc74-4242-4579-8b83-d7a537e082b5",
   "metadata": {},
   "source": [
    "## üßπ 3. Data Cleaning & Quality Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa6405-cbaa-4291-810f-ccb99aedbd6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 1: Handle Missing values of age, and salary\n",
    "Handle missing values in age and salary columns using appropriate strategies:\n",
    "- For age: Use median (robust to outliers)\n",
    "- For salary: Use median (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b49db1-ac54-410b-9092-534ea82cec0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.170071Z",
     "iopub.status.busy": "2025-07-30T01:14:13.169640Z",
     "iopub.status.idle": "2025-07-30T01:14:13.182116Z",
     "shell.execute_reply": "2025-07-30T01:14:13.181403Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.169993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Missing Value Patterns:\n",
      "Missing Age values:\n",
      "       age   salary department\n",
      "0      NaN      NaN  Marketing\n",
      "17     NaN  50000.0         IT\n",
      "41     NaN      NaN         IT\n",
      "51     NaN  50000.0         HR\n",
      "58     NaN  60000.0         IT\n",
      "...    ...      ...        ...\n",
      "49890  NaN  70000.0  Marketing\n",
      "49943  NaN  50000.0         HR\n",
      "49986  NaN      NaN    Finance\n",
      "49987  NaN  60000.0         IT\n",
      "49996  NaN      NaN        NaN\n",
      "\n",
      "[2500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing patterns\n",
    "print(\"\\nüìä Missing Value Patterns:\")\n",
    "print(\"Missing Age values:\")\n",
    "print(df[df['age'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b91f6e6-b8a0-4528-8009-dbae08ae21f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.183480Z",
     "iopub.status.busy": "2025-07-30T01:14:13.183071Z",
     "iopub.status.idle": "2025-07-30T01:14:13.194546Z",
     "shell.execute_reply": "2025-07-30T01:14:13.193701Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.183451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Salary values\n",
      "        age  salary department\n",
      "0       NaN     NaN  Marketing\n",
      "2      33.0     NaN  Marketing\n",
      "6      60.0     NaN        NaN\n",
      "11     29.0     NaN         HR\n",
      "13     48.0     NaN        NaN\n",
      "...     ...     ...        ...\n",
      "49981  72.0     NaN  Marketing\n",
      "49983  67.0     NaN         HR\n",
      "49986   NaN     NaN    Finance\n",
      "49992  43.0     NaN         HR\n",
      "49996   NaN     NaN        NaN\n",
      "\n",
      "[16152 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Salary values\")\n",
    "print(df[df['salary'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12df9538-38f3-42d2-a62e-08e5ba0af6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.195869Z",
     "iopub.status.busy": "2025-07-30T01:14:13.195436Z",
     "iopub.status.idle": "2025-07-30T01:14:13.205169Z",
     "shell.execute_reply": "2025-07-30T01:14:13.204464Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.195814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Median 48.0\n",
      "Salary Median 60000.0\n"
     ]
    }
   ],
   "source": [
    "# Get the median values for age, and salary\n",
    "age_median = df['age'].median()\n",
    "salary_median = df['salary'].median()\n",
    "print(\"Age Median\", age_median)\n",
    "print(\"Salary Median\", salary_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2bc0570-6fc5-464c-81d8-a02a3adba273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.206516Z",
     "iopub.status.busy": "2025-07-30T01:14:13.206206Z",
     "iopub.status.idle": "2025-07-30T01:14:13.214150Z",
     "shell.execute_reply": "2025-07-30T01:14:13.212741Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.206487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values of age with age_median\n",
    "df['age'] = df['age'].fillna(age_median)\n",
    "# Fill missing values of salary with salary_median\n",
    "df['salary'] = df['salary'].fillna(salary_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fb165-2329-462f-a31e-95c68398c2bd",
   "metadata": {},
   "source": [
    "#### Age & Salary columns missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85aacbe-1f52-4c17-8e8f-6ad235eb3c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.216231Z",
     "iopub.status.busy": "2025-07-30T01:14:13.215890Z",
     "iopub.status.idle": "2025-07-30T01:14:13.236102Z",
     "shell.execute_reply": "2025-07-30T01:14:13.235092Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.216204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "name              0\n",
       "age               0\n",
       "salary            0\n",
       "hire_date      4937\n",
       "profile        5051\n",
       "department    10116\n",
       "bonus          4974\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c09aa2-0bc1-473f-8c76-f19774a5d739",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2: Handle Missing values of Department\n",
    "Handle missing values in categorical columns:\n",
    "- For department: Use 'Unknown' category\n",
    "- This preserves the information that the department was missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47976d92-55aa-47c2-9ff7-6a4e17c63130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.237551Z",
     "iopub.status.busy": "2025-07-30T01:14:13.237121Z",
     "iopub.status.idle": "2025-07-30T01:14:13.251668Z",
     "shell.execute_reply": "2025-07-30T01:14:13.250959Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.237417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the missing values for Department\n",
      "\n",
      "Missing Department Missing values\n",
      "        age   salary department\n",
      "6      60.0  60000.0        NaN\n",
      "13     48.0  60000.0        NaN\n",
      "14     29.0  60000.0        NaN\n",
      "15     27.0  70000.0        NaN\n",
      "16     57.0  70000.0        NaN\n",
      "...     ...      ...        ...\n",
      "49985  35.0  50000.0        NaN\n",
      "49988  25.0  50000.0        NaN\n",
      "49989  33.0  50000.0        NaN\n",
      "49996  48.0  60000.0        NaN\n",
      "49998  61.0  50000.0        NaN\n",
      "\n",
      "[10116 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the missing values for Department\\n\")\n",
    "print(\"Missing Department Missing values\")\n",
    "print(df[df['department'].isnull()][['age', 'salary', 'department']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e3c4fe-2eff-4254-afc8-72f131d1337a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.253118Z",
     "iopub.status.busy": "2025-07-30T01:14:13.252803Z",
     "iopub.status.idle": "2025-07-30T01:14:13.262617Z",
     "shell.execute_reply": "2025-07-30T01:14:13.261242Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.253090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill the missing values in department with 'Unknown'\n",
    "df['department'] = df['department'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cef80-1465-4bf7-a5dd-77c98d726590",
   "metadata": {},
   "source": [
    "#### Department column missing values are filled with the respective median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cc852e-7cad-4d18-bd6a-b5399e65ebb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.263954Z",
     "iopub.status.busy": "2025-07-30T01:14:13.263647Z",
     "iopub.status.idle": "2025-07-30T01:14:13.286046Z",
     "shell.execute_reply": "2025-07-30T01:14:13.285147Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.263927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column\n",
      "id               0\n",
      "name             0\n",
      "age              0\n",
      "salary           0\n",
      "hire_date     4937\n",
      "profile       5051\n",
      "department       0\n",
      "bonus         4974\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Marketing', 'HR', 'Finance', 'Unknown', 'IT'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the Age & Salary data\n",
    "df.head()\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column\")\n",
    "print(df.isnull().sum())\n",
    "# Check unique values in the department column\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df4a53-6359-4802-979d-df7070a57e9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 3: Parse and Extract Profile Information\n",
    "Devide Profile Column into 3 different columns i.e., Address, Phone, Email   \n",
    "\n",
    "Parse JSON profile data and extract structured information:\n",
    "- Extract address, phone, and email into separate columns\n",
    "- Handle malformed JSON gracefully\n",
    "- Maintain data integrity during extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e044cc-fb5c-4b9a-a5f2-bfb99b07add1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.287531Z",
     "iopub.status.busy": "2025-07-30T01:14:13.287035Z",
     "iopub.status.idle": "2025-07-30T01:14:13.668836Z",
     "shell.execute_reply": "2025-07-30T01:14:13.667848Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.287502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top rows from profile column \n",
      "\n",
      "0    {\"address\": \"Street 40, City 17\", \"phone\": \"92...\n",
      "1    {\"address\": \"Street 82, City 15\", \"phone\": \"42...\n",
      "2                                                  NaN\n",
      "3                                                  NaN\n",
      "4    {\"address\": \"Street 12, City 18\", \"phone\": \"42...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Profile column values current data type\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "\n",
    "# Find the first non-null value in the column\n",
    "profile_first_value = df['profile'].dropna().iloc[0]\n",
    "# Print its type\n",
    "print(\"\\nProfile column values current data type\")\n",
    "print(type(profile_first_value))\n",
    "\n",
    "# If your 'profile' column already contains Python dictionaries, not JSON strings.\n",
    "# You do not need to parse it with json.loads(). The data is ready to be used directly.\n",
    "\n",
    "# Convert profile JSON strings into dictionaries\n",
    "df['profile'] = df['profile'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10b5d994-5d55-438e-93fd-ff2042cffffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.670366Z",
     "iopub.status.busy": "2025-07-30T01:14:13.669776Z",
     "iopub.status.idle": "2025-07-30T01:14:13.692401Z",
     "shell.execute_reply": "2025-07-30T01:14:13.691719Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.670334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Address Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 40, City 17', 'phone': '92...\n",
      "1    {'address': 'Street 82, City 15', 'phone': '42...\n",
      "2                                                   {}\n",
      "3                                                   {}\n",
      "4    {'address': 'Street 12, City 18', 'phone': '42...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created address column \n",
      "\n",
      "0    Street 40, City 17\n",
      "1    Street 82, City 15\n",
      "2                  None\n",
      "3                  None\n",
      "4    Street 12, City 18\n",
      "Name: address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Address Field\n",
    "print(\"Extract Address Field....\\n\")\n",
    "# Create new 'address' column by extracting from 'profile' dictionaries\n",
    "df['address'] = df['profile'].apply(lambda x: x.get('address', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created address column \\n\")\n",
    "print(df['address'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5fbe45-27ac-4eef-992f-79d4895060a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.693740Z",
     "iopub.status.busy": "2025-07-30T01:14:13.693368Z",
     "iopub.status.idle": "2025-07-30T01:14:13.713340Z",
     "shell.execute_reply": "2025-07-30T01:14:13.712446Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.693712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Phone Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 40, City 17', 'phone': '92...\n",
      "1    {'address': 'Street 82, City 15', 'phone': '42...\n",
      "2                                                   {}\n",
      "3                                                   {}\n",
      "4    {'address': 'Street 12, City 18', 'phone': '42...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created phone column \n",
      "\n",
      "0    9277021151\n",
      "1    4253217714\n",
      "2          None\n",
      "3          None\n",
      "4    4241355181\n",
      "Name: phone, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract Phone Field\n",
    "print(\"Extract Phone Field....\\n\")\n",
    "# Create new 'phone' column by extracting from 'profile' dictionaries\n",
    "df['phone'] = df['profile'].apply(lambda x: x.get('phone', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created phone column \\n\")\n",
    "print(df['phone'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebdb099-5095-4149-b957-119ae9fccaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.714848Z",
     "iopub.status.busy": "2025-07-30T01:14:13.714405Z",
     "iopub.status.idle": "2025-07-30T01:14:13.735385Z",
     "shell.execute_reply": "2025-07-30T01:14:13.734596Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.714812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Email Field....\n",
      "\n",
      "Top rows from profile column \n",
      "\n",
      "0    {'address': 'Street 40, City 17', 'phone': '92...\n",
      "1    {'address': 'Street 82, City 15', 'phone': '42...\n",
      "2                                                   {}\n",
      "3                                                   {}\n",
      "4    {'address': 'Street 12, City 18', 'phone': '42...\n",
      "Name: profile, dtype: object\n",
      "\n",
      "Top rows from newly created email column \n",
      "\n",
      "0    email_937@example.com\n",
      "1    email_757@example.com\n",
      "2                     None\n",
      "3                     None\n",
      "4    email_227@example.com\n",
      "Name: email, dtype: object\n",
      "\n",
      "‚úÖ Profile fields extracted:\n"
     ]
    }
   ],
   "source": [
    "# Extract Email Field\n",
    "print(\"Extract Email Field....\\n\")\n",
    "# Create new 'email' column by extracting from 'profile' dictionaries\n",
    "df['email'] = df['profile'].apply(lambda x: x.get('email', None))  # Returns None if no address key\n",
    "\n",
    "print(\"Top rows from profile column \\n\")\n",
    "print(df['profile'].head())\n",
    "print(\"\\nTop rows from newly created email column \\n\")\n",
    "print(df['email'].head())\n",
    "\n",
    "print(f\"\\n‚úÖ Profile fields extracted:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee1aeb4-dac9-40f4-8455-1a24e1e8ff1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.736912Z",
     "iopub.status.busy": "2025-07-30T01:14:13.736577Z",
     "iopub.status.idle": "2025-07-30T01:14:13.751474Z",
     "shell.execute_reply": "2025-07-30T01:14:13.750670Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.736885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns before dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'profile', 'department', 'bonus', 'address', 'phone', 'email']\n",
      "\n",
      "Columns in new DataFrame after dropping profile:\n",
      "['id', 'name', 'age', 'salary', 'hire_date', 'department', 'bonus', 'address', 'phone', 'email']\n"
     ]
    }
   ],
   "source": [
    "# Now drop the profile column\n",
    "print(\"\\nColumns before dropping profile:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Without inplace=True (df remains unchanged)\n",
    "cleaned_df = df.drop(columns=['profile'])\n",
    "\n",
    "# With inplace=True (df is modified directly)\n",
    "#df.drop(columns=['profile'], inplace=True)\n",
    "\n",
    "print(\"\\nColumns in new DataFrame after dropping profile:\")\n",
    "# print(df.columns.tolist())\n",
    "print(cleaned_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb385e-e37f-41ec-9c6b-5634419dc89a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Save cleaned data into new CSV and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f9bfbc-83de-433d-8461-d43f5d088731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:13.752990Z",
     "iopub.status.busy": "2025-07-30T01:14:13.752516Z",
     "iopub.status.idle": "2025-07-30T01:14:14.184396Z",
     "shell.execute_reply": "2025-07-30T01:14:14.183655Z",
     "shell.execute_reply.started": "2025-07-30T01:14:13.752961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\n",
      "‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\n",
      "\n",
      "Uploading dataset to s3 bucket: sagemaker-us-east-1-975050014577\n",
      "Dataset 'mock_data.csv' uploaded to: s3://sagemaker-us-east-1-975050014577/output/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Saving cleaned data to: 'data/cleaned_data.csv' ...\")\n",
    "cleaned_df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
    "print(\"‚úÖ Cleaned data saved to: 'data/cleaned_data.csv'\")\n",
    "\n",
    "print(f\"\\nUploading dataset to s3 bucket: {bucket}\")\n",
    "s3.meta.client.upload_file('data/cleaned_data.csv', bucket, 'output/cleaned_data.csv')\n",
    "print(f\"Dataset 'mock_data.csv' uploaded to: s3://{bucket}/output/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb68ace-9dce-4caf-9217-a25106886373",
   "metadata": {},
   "source": [
    "## 4. Data Transformation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41937110-6255-4cc3-a4ce-cfb0d7fb91d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 1: Load the cleaned dataset into new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f36252c-0d27-44c4-9a51-25876ee35fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.185751Z",
     "iopub.status.busy": "2025-07-30T01:14:14.185305Z",
     "iopub.status.idle": "2025-07-30T01:14:14.364807Z",
     "shell.execute_reply": "2025-07-30T01:14:14.364067Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.185720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>department</th>\n",
       "      <th>bonus</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Name_103</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>7236.0</td>\n",
       "      <td>Street 40, City 17</td>\n",
       "      <td>9.277021e+09</td>\n",
       "      <td>email_937@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Name_436</td>\n",
       "      <td>24.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>HR</td>\n",
       "      <td>9162.0</td>\n",
       "      <td>Street 82, City 15</td>\n",
       "      <td>4.253218e+09</td>\n",
       "      <td>email_757@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Name_861</td>\n",
       "      <td>33.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Name_271</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>Finance</td>\n",
       "      <td>8982.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Name_107</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>Street 12, City 18</td>\n",
       "      <td>4.241355e+09</td>\n",
       "      <td>email_227@example.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name   age   salary   hire_date department   bonus  \\\n",
       "0   1  Name_103  48.0  60000.0  2025-05-16  Marketing  7236.0   \n",
       "1   2  Name_436  24.0  70000.0  2022-10-12         HR  9162.0   \n",
       "2   3  Name_861  33.0  60000.0  2022-08-12  Marketing     NaN   \n",
       "3   4  Name_271  50.0  50000.0  2017-03-29    Finance  8982.0   \n",
       "4   5  Name_107  50.0  70000.0  2016-04-18  Marketing  1856.0   \n",
       "\n",
       "              address         phone                  email  \n",
       "0  Street 40, City 17  9.277021e+09  email_937@example.com  \n",
       "1  Street 82, City 15  4.253218e+09  email_757@example.com  \n",
       "2                 NaN           NaN                    NaN  \n",
       "3                 NaN           NaN                    NaN  \n",
       "4  Street 12, City 18  4.241355e+09  email_227@example.com  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = pd.read_csv(f's3://{bucket}/output/cleaned_data.csv')\n",
    "transform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a3a74-21ab-42bb-a0c0-3654bd30762e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2: Feature Engineering - Salary Categorization\n",
    "Create salary categories for easier analysis and modeling.  \n",
    "This converts continuous salary into ordinal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8273466c-9379-4d78-b658-0837258d5cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.366526Z",
     "iopub.status.busy": "2025-07-30T01:14:14.365880Z",
     "iopub.status.idle": "2025-07-30T01:14:14.382436Z",
     "shell.execute_reply": "2025-07-30T01:14:14.381677Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.366494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Salary Categories...\n",
      "Sample data after adding the 'salary_category' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary salary_category\n",
       "0  60000.0          medium\n",
       "1  70000.0          medium\n",
       "2  60000.0          medium\n",
       "3  50000.0             low\n",
       "4  70000.0          medium"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Salary Categories...\")\n",
    "# Define the bins and labels\n",
    "bins = [0, 50000, 70000, 100000]\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['salary_category'] = pd.cut(df['salary'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"Sample data after adding the 'salary_category' column: \\n\")\n",
    "transform_df[['salary', 'salary_category']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5499d-ae91-4868-a45a-873757984b1e",
   "metadata": {},
   "source": [
    "### Step 3: Feature Engineering - Age Groups  \n",
    "Create age groups for demographic analysis.  \n",
    "This helps in understanding age-based patterns in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a60a508-591e-4bc8-a8dc-21b8ef5f15d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.384182Z",
     "iopub.status.busy": "2025-07-30T01:14:14.383543Z",
     "iopub.status.idle": "2025-07-30T01:14:14.400068Z",
     "shell.execute_reply": "2025-07-30T01:14:14.399406Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.384101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating Age Groups...\n",
      "Age group distribution:\n",
      "age_group\n",
      "Experienced     18413\n",
      "Senior          10091\n",
      "Mid Career       7779\n",
      "Early Career     7530\n",
      "Young            6187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data after adding the 'age_group' column: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Early Career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     age_group\n",
       "0  48.0        Senior\n",
       "1  24.0         Young\n",
       "2  33.0  Early Career\n",
       "3  50.0        Senior\n",
       "4  50.0        Senior"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüîß Creating Age Groups...\")\n",
    "# Define age bins and labels\n",
    "age_bins = [0, 25, 35, 45, 55, float('inf')]\n",
    "age_labels = ['Young', 'Early Career', 'Mid Career', 'Senior', 'Experienced']\n",
    "\n",
    "# Create a new column 'salary_category'\n",
    "transform_df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "# Age group distribution\n",
    "print(f\"Age group distribution:\")\n",
    "print(transform_df['age_group'].value_counts())\n",
    "\n",
    "# Print sample data after adding the 'salary_category' column\n",
    "print(\"\\nSample data after adding the 'age_group' column: \\n\")\n",
    "transform_df[['age', 'age_group']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4dd85-4808-4092-84a7-9884b356b2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T17:33:57.674942Z",
     "iopub.status.busy": "2025-07-27T17:33:57.674660Z",
     "iopub.status.idle": "2025-07-27T17:33:57.686040Z",
     "shell.execute_reply": "2025-07-27T17:33:57.685195Z",
     "shell.execute_reply.started": "2025-07-27T17:33:57.674921Z"
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Remove missing values in bonus (is the target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3e6dcb0-6ddd-4aa1-b71c-23f7643ca281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.404190Z",
     "iopub.status.busy": "2025-07-30T01:14:14.403618Z",
     "iopub.status.idle": "2025-07-30T01:14:14.439123Z",
     "shell.execute_reply": "2025-07-30T01:14:14.438286Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.404168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing Values Analysis before Removing Missing:\n",
      "\n",
      "id                    0\n",
      "name                  0\n",
      "age                   0\n",
      "salary                0\n",
      "hire_date          4937\n",
      "department            0\n",
      "bonus              4974\n",
      "address            5051\n",
      "phone              5051\n",
      "email              5051\n",
      "salary_category       0\n",
      "age_group             0\n",
      "dtype: int64\n",
      "\n",
      "‚ùì Missing Values Analysis after Removing Missing:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "name                  0\n",
       "age                   0\n",
       "salary                0\n",
       "hire_date          4450\n",
       "department            0\n",
       "bonus                 0\n",
       "address            4541\n",
       "phone              4541\n",
       "email              4541\n",
       "salary_category       0\n",
       "age_group             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n‚ùì Missing Values Analysis before Removing Missing:\\n\")\n",
    "print(transform_df.isnull().sum())\n",
    "\n",
    "# Remove missing rows for bonus\n",
    "transform_df = transform_df[transform_df['bonus'].notna()]\n",
    "print(\"\\n‚ùì Missing Values Analysis after Removing Missing:\\n\")\n",
    "transform_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b2889-5c28-4965-a604-33d779b8311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:12:34.504037Z",
     "iopub.status.busy": "2025-07-27T18:12:34.503634Z",
     "iopub.status.idle": "2025-07-27T18:12:34.507819Z",
     "shell.execute_reply": "2025-07-27T18:12:34.506903Z",
     "shell.execute_reply.started": "2025-07-27T18:12:34.504011Z"
    }
   },
   "source": [
    "### Step 5: Feature Engineering - One-Hot Encoding on department, age_group & salary_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd51715-3c3e-4ea4-9960-ce5f7364c44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.440620Z",
     "iopub.status.busy": "2025-07-30T01:14:14.440318Z",
     "iopub.status.idle": "2025-07-30T01:14:14.484271Z",
     "shell.execute_reply": "2025-07-30T01:14:14.483508Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.440593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows with boolean values\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  48.0  60000.0  2025-05-16  7236.0  Street 40, City 17   \n",
      "1   2  Name_436  24.0  70000.0  2022-10-12  9162.0  Street 82, City 15   \n",
      "3   4  Name_271  50.0  50000.0  2017-03-29  8982.0                 NaN   \n",
      "4   5  Name_107  50.0  70000.0  2016-04-18  1856.0  Street 12, City 18   \n",
      "5   6   Name_72  31.0  50000.0  2020-12-18  3873.0  Street 77, City 39   \n",
      "\n",
      "          phone                  email  dept_Finance  ...  dept_Marketing  \\\n",
      "0  9.277021e+09  email_937@example.com         False  ...            True   \n",
      "1  4.253218e+09  email_757@example.com         False  ...           False   \n",
      "3           NaN                    NaN          True  ...           False   \n",
      "4  4.241355e+09  email_227@example.com         False  ...            True   \n",
      "5  1.233984e+09  email_395@example.com          True  ...           False   \n",
      "\n",
      "   dept_Unknown  age_Young  age_Early Career  age_Mid Career  age_Senior  \\\n",
      "0         False      False             False           False        True   \n",
      "1         False       True             False           False       False   \n",
      "3         False      False             False           False        True   \n",
      "4         False      False             False           False        True   \n",
      "5         False      False              True           False       False   \n",
      "\n",
      "   age_Experienced  salary_low  salary_medium  salary_high  \n",
      "0            False       False           True        False  \n",
      "1            False       False           True        False  \n",
      "3            False        True          False        False  \n",
      "4            False       False           True        False  \n",
      "5            False        True          False        False  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Top 5 rows with numberic values\n",
      "\n",
      "   id      name   age   salary   hire_date   bonus             address  \\\n",
      "0   1  Name_103  48.0  60000.0  2025-05-16  7236.0  Street 40, City 17   \n",
      "1   2  Name_436  24.0  70000.0  2022-10-12  9162.0  Street 82, City 15   \n",
      "3   4  Name_271  50.0  50000.0  2017-03-29  8982.0                 NaN   \n",
      "4   5  Name_107  50.0  70000.0  2016-04-18  1856.0  Street 12, City 18   \n",
      "5   6   Name_72  31.0  50000.0  2020-12-18  3873.0  Street 77, City 39   \n",
      "\n",
      "          phone                  email  dept_Finance  ...  dept_Marketing  \\\n",
      "0  9.277021e+09  email_937@example.com             0  ...               1   \n",
      "1  4.253218e+09  email_757@example.com             0  ...               0   \n",
      "3           NaN                    NaN             1  ...               0   \n",
      "4  4.241355e+09  email_227@example.com             0  ...               1   \n",
      "5  1.233984e+09  email_395@example.com             1  ...               0   \n",
      "\n",
      "   dept_Unknown  age_Young  age_Early Career  age_Mid Career  age_Senior  \\\n",
      "0             0          0                 0               0           1   \n",
      "1             0          1                 0               0           0   \n",
      "3             0          0                 0               0           1   \n",
      "4             0          0                 0               0           1   \n",
      "5             0          0                 1               0           0   \n",
      "\n",
      "   age_Experienced  salary_low  salary_medium  salary_high  \n",
      "0                0           0              1            0  \n",
      "1                0           0              1            0  \n",
      "3                0           1              0            0  \n",
      "4                0           0              1            0  \n",
      "5                0           1              0            0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "transform_df = pd.get_dummies(transform_df, columns=['department', 'age_group', 'salary_category'], prefix=['dept', 'age', 'salary'])\n",
    "print(\"Top 5 rows with boolean values\")\n",
    "print(transform_df.head())\n",
    "\n",
    "bool_cols = transform_df.select_dtypes(include='bool').columns\n",
    "transform_df[bool_cols] = transform_df[bool_cols].astype(int)\n",
    "\n",
    "print(\"\\nTop 5 rows with numberic values\\n\")\n",
    "print(transform_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc32b5-5ddc-4dd4-b57f-7593195d4d21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 6: Feature Engineering | Calculate Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68f7db69-be7e-4cd4-af46-65253bc71d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.485719Z",
     "iopub.status.busy": "2025-07-30T01:14:14.485316Z",
     "iopub.status.idle": "2025-07-30T01:14:14.515752Z",
     "shell.execute_reply": "2025-07-30T01:14:14.515026Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.485690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert hire_date to datetime\n",
      "0   2025-05-16\n",
      "1   2022-10-12\n",
      "3   2017-03-29\n",
      "4   2016-04-18\n",
      "5   2020-12-18\n",
      "Name: hire_date, dtype: datetime64[ns]\n",
      "Calculate Tenure in Days....\n",
      "Calculated Tenure Days\n",
      "0          75.0\n",
      "1        1022.0\n",
      "3        3045.0\n",
      "4        3390.0\n",
      "5        1685.0\n",
      "          ...  \n",
      "49994    1179.0\n",
      "49995     208.0\n",
      "49996       NaN\n",
      "49998    3609.0\n",
      "49999    3491.0\n",
      "Name: tenure_days, Length: 45026, dtype: float64\n",
      "Handle Missing values of tenure_days\n",
      "Tenure Days after handled missing days\n",
      "0          75.0\n",
      "1        1022.0\n",
      "3        3045.0\n",
      "4        3390.0\n",
      "5        1685.0\n",
      "          ...  \n",
      "49994    1179.0\n",
      "49995     208.0\n",
      "49996    1836.0\n",
      "49998    3609.0\n",
      "49999    3491.0\n",
      "Name: tenure_days, Length: 45026, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert hire_date to datetime\")\n",
    "transform_df['hire_date'] = pd.to_datetime(transform_df['hire_date'], errors='coerce')\n",
    "print(transform_df['hire_date'].head())\n",
    "# print(transform_df.dtypes)\n",
    "\n",
    "# non_date_rows = transform_df[transform_df['hire_date'].apply(lambda x: isinstance(x, str))]\n",
    "# print(\"non date rows:\")\n",
    "# print(non_date_rows)\n",
    "\n",
    "print(\"Calculate Tenure in Days....\")\n",
    "transform_df['tenure_days'] = (pd.Timestamp('now') - transform_df['hire_date']).dt.days\n",
    "\n",
    "print(\"Calculated Tenure Days\")\n",
    "print(transform_df['tenure_days'])\n",
    "\n",
    "print(\"Handle Missing values of tenure_days\")\n",
    "transform_df['tenure_days'] = transform_df['tenure_days'].fillna(transform_df['tenure_days'].median())\n",
    "\n",
    "print(\"Tenure Days after handled missing days\")\n",
    "print(transform_df['tenure_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51943479-aee6-4538-9ad4-1e6571d6a661",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 7: Feature Engineering | Removing Irrelevant or non-predictive columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c1a7779-1960-44d6-869a-3e52055a6fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.517163Z",
     "iopub.status.busy": "2025-07-30T01:14:14.516738Z",
     "iopub.status.idle": "2025-07-30T01:14:14.531258Z",
     "shell.execute_reply": "2025-07-30T01:14:14.530543Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.517131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping ID, Address, Phone, Name, Hire Date, and Email.....\n",
      "After dropping ID, Address, Phone, Name, Hire Date, and Email, dataset look like\n",
      "    age   salary   bonus  dept_Finance  dept_HR  dept_IT  dept_Marketing  \\\n",
      "0  48.0  60000.0  7236.0             0        0        0               1   \n",
      "1  24.0  70000.0  9162.0             0        1        0               0   \n",
      "3  50.0  50000.0  8982.0             1        0        0               0   \n",
      "4  50.0  70000.0  1856.0             0        0        0               1   \n",
      "5  31.0  50000.0  3873.0             1        0        0               0   \n",
      "\n",
      "   dept_Unknown  age_Young  age_Early Career  age_Mid Career  age_Senior  \\\n",
      "0             0          0                 0               0           1   \n",
      "1             0          1                 0               0           0   \n",
      "3             0          0                 0               0           1   \n",
      "4             0          0                 0               0           1   \n",
      "5             0          0                 1               0           0   \n",
      "\n",
      "   age_Experienced  salary_low  salary_medium  salary_high  tenure_days  \n",
      "0                0           0              1            0         75.0  \n",
      "1                0           0              1            0       1022.0  \n",
      "3                0           1              0            0       3045.0  \n",
      "4                0           0              1            0       3390.0  \n",
      "5                0           1              0            0       1685.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping ID, Address, Phone, Name, Hire Date, and Email.....\")\n",
    "transform_df.drop(columns=['id', 'address', 'phone', 'email', 'name', 'hire_date'], inplace=True)\n",
    "print(\"After dropping ID, Address, Phone, Name, Hire Date, and Email, dataset look like\")\n",
    "print(transform_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc636561-1dd7-464e-b908-de230785c662",
   "metadata": {},
   "source": [
    "### Step 8: Save the transformed DataFrame to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "effa94fc-c979-4bda-a3bd-fb00e38457ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T01:14:14.532198Z",
     "iopub.status.busy": "2025-07-30T01:14:14.531976Z",
     "iopub.status.idle": "2025-07-30T01:14:14.808683Z",
     "shell.execute_reply": "2025-07-30T01:14:14.807846Z",
     "shell.execute_reply.started": "2025-07-30T01:14:14.532180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Transformed data csv to: 'data/transformed_data.csv' ...\n",
      "\n",
      "Transformed data csv saved to: 'data/transformed_data.csv'\n",
      "Transformed data 'transformed_data.csv' uploaded to: s3://sagemaker-us-east-1-975050014577/output/transformed_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Transformed data csv to: 'data/transformed_data.csv' ...\")\n",
    "transform_df.to_csv(\"data/transformed_data.csv\", index=False)\n",
    "print(\"\\nTransformed data csv saved to: 'data/transformed_data.csv'\")\n",
    "\n",
    "s3.meta.client.upload_file('data/transformed_data.csv', bucket, 'output/transformed_data.csv')\n",
    "print(f\"Transformed data 'transformed_data.csv' uploaded to: s3://{bucket}/output/transformed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
